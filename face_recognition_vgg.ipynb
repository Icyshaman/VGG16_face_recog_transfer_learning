{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using VGG16 for Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top = False, input_shape=(img_rows, img_cols, 3))\n",
    "\n",
    "for  layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function returns fc_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_head(model, num_classes):\n",
    "    fc_head = model.output\n",
    "    fc_head = Flatten(name = \"flatten\")(fc_head)\n",
    "    fc_head = Dense(1024, activation='relu')(fc_head)\n",
    "    fc_head = Dense(512, activation='relu')(fc_head)\n",
    "    fc_head = Dense(256, activation='relu')(fc_head)\n",
    "    fc_head = Dense(num_classes, activation='softmax')(fc_head)\n",
    "    return fc_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding fc_head to VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# assign no. of classes available to num_classes\n",
    "num_classes = 10\n",
    "\n",
    "fc_head = fully_connected_head(model, num_classes)\n",
    "\n",
    "model = Model(inputs = model.input, outputs = fc_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset and performing data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# assign path of your training dataset to train_data_dir\n",
    "# assign path of your validation dataset to validation_data_dir\n",
    "train_data_dir = 'human_face/train/'\n",
    "validation_data_dir = 'human_face/test/'\n",
    " \n",
    "train_data_aug = ImageDataGenerator(rescale=1./255, rotation_range=45, \n",
    "                                             width_shift_range=0.3, height_shift_range=0.3,\n",
    "                                             horizontal_flip=True, fill_mode='nearest')\n",
    " \n",
    "validation_data_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    " \n",
    "train_data_augmentation = train_data_aug.flow_from_directory(train_data_dir, target_size=(img_rows, img_cols),\n",
    "                                                    batch_size=batch_size, class_mode='categorical')\n",
    " \n",
    "validation_data_augmentation = validation_data_aug.flow_from_directory(validation_data_dir, target_size=(img_rows, img_cols),\n",
    "                                                              batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from PIL import Image\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"face_rec_vgg16.h5\", monitor=\"val_loss\",\n",
    "                              mode=\"min\", save_best_only = True, verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3,\n",
    "                          verbose = 1, restore_best_weights = True)\n",
    "\n",
    "callbacks = [earlystop, checkpoint]\n",
    " \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = 450\n",
    "nb_validation_samples = 50\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit_generator(train_data_augmentation, steps_per_epoch = nb_train_samples // batch_size,\n",
    "                              epochs = epochs, callbacks = callbacks, validation_data = validation_data_augmentation,\n",
    "                              validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('face_rec_vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "human_face_dict = {\"[0]\": \"Ariel_Sharon\", \n",
    "                      \"[1]\": \"Colin_Powell\",\n",
    "                      \"[2]\": \"Donald_Rumsfeld\",\n",
    "                      \"[3]\": \"George_W_Bush\",\n",
    "                      \"[4]\": \"Gerhard_Schroeder\",\n",
    "                      \"[5]\": \"Hugo_Chavez\",\n",
    "                      \"[6]\": \"Jean_Chretien\",\n",
    "                      \"[7]\": \"John_Ashcroft\",\n",
    "                      \"[8]\": \"Junichiro_Koizumi\",\n",
    "                      \"[9]\": \"Tony_Blair\"}\n",
    "\n",
    "human_face_dict_n = {\"n0\": \"Ariel_Sharon\", \n",
    "                      \"n1\": \"Colin_Powell\",\n",
    "                      \"n2\": \"Donald_Rumsfeld\",\n",
    "                      \"n3\": \"George_W_Bush\",\n",
    "                      \"n4\": \"Gerhard_Schroeder\",\n",
    "                      \"n5\": \"Hugo_Chavez\",\n",
    "                      \"n6\": \"Jean_Chretien\",\n",
    "                      \"n7\": \"John_Ashcroft\",\n",
    "                      \"n8\": \"Junichiro_Koizumi\",\n",
    "                      \"n9\": \"Tony_Blair\"}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    human = human_face_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, human, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + human_face_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"human_face/test/\")\n",
    "    if input_im is None:\n",
    "        continue\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
